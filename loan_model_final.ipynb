{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e407aa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\karti\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install shap seaborn fairlearn xgboost -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f5e7a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from fairlearn.metrics import MetricFrame, demographic_parity_difference, equalized_odds_difference\n",
    "from fairlearn.reductions import ExponentiatedGradient, DemographicParity\n",
    "from scipy.stats import skew, boxcox\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d29ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "        self.categorical_cols = ['Gender', 'Race', 'Employment_Type', 'Education_Level',\n",
    "                                'Citizenship_Status', 'Language_Proficiency',\n",
    "                                'Disability_Status', 'Criminal_Record', 'Zip_Code_Group']\n",
    "        self.numerical_cols = ['Age', 'Income', 'Credit_Score', 'Loan_Amount']\n",
    "        self.fitted = False\n",
    "\n",
    "    def preprocess(self, df, is_train=True):\n",
    "        \"\"\"Preprocess the dataset, returning features and sensitive attributes.\"\"\"\n",
    "        logging.info(\"Starting preprocessing (is_train=%s)\", is_train)\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Drop redundant feature\n",
    "        df = df.drop(columns=['Age_Group'], errors='ignore')\n",
    "        \n",
    "        # Feature engineering\n",
    "        df['Income_to_Loan_Ratio'] = df['Income'] / (df['Loan_Amount'] + 1e-6)\n",
    "        numerical_cols = self.numerical_cols + ['Income_to_Loan_Ratio']\n",
    "        \n",
    "        # Check for NaN in input\n",
    "        if df[numerical_cols].isna().any().any():\n",
    "            raise ValueError(f\"NaN in numerical columns: {df[numerical_cols].columns[df[numerical_cols].isna().any()].tolist()}\")\n",
    "        if df[self.categorical_cols].isna().any().any():\n",
    "            raise ValueError(f\"NaN in categorical columns: {df[self.categorical_cols].columns[df[self.categorical_cols].isna().any()].tolist()}\")\n",
    "        \n",
    "        # Extract sensitive features for auditing\n",
    "        sensitive_features = df[['Gender', 'Race', 'Zip_Code_Group', 'Citizenship_Status', 'Criminal_Record']].copy()\n",
    "        \n",
    "        # Encode categorical features\n",
    "        if is_train:\n",
    "            self.fitted = True\n",
    "            encoded = self.encoder.fit_transform(df[self.categorical_cols])\n",
    "            encoded_cols = self.encoder.get_feature_names_out(self.categorical_cols)\n",
    "            encoded_df = pd.DataFrame(encoded, columns=encoded_cols, index=df.index)\n",
    "        else:\n",
    "            if not self.fitted:\n",
    "                raise ValueError(\"Preprocessor must be fitted on training data first\")\n",
    "            try:\n",
    "                encoded = self.encoder.transform(df[self.categorical_cols])\n",
    "                encoded_cols = self.encoder.get_feature_names_out(self.categorical_cols)\n",
    "                encoded_df = pd.DataFrame(encoded, columns=encoded_cols, index=df.index)\n",
    "            except ValueError as e:\n",
    "                raise ValueError(f\"Unknown categories in test data: {str(e)}\")\n",
    "        \n",
    "        # Check for NaN after encoding\n",
    "        if encoded_df.isna().any().any():\n",
    "            raise ValueError(f\"NaN in encoded columns: {encoded_df.columns[encoded_df.isna().any()].tolist()}\")\n",
    "        \n",
    "        # Scale numerical features\n",
    "        if is_train:\n",
    "            scaled = self.scaler.fit_transform(df[numerical_cols])\n",
    "        else:\n",
    "            scaled = self.scaler.transform(df[numerical_cols])\n",
    "        scaled_df = pd.DataFrame(scaled, columns=numerical_cols, index=df.index)\n",
    "        \n",
    "        # Check for NaN after scaling\n",
    "        if scaled_df.isna().any().any():\n",
    "            raise ValueError(f\"NaN in scaled columns: {scaled_df.columns[scaled_df.isna().any()].tolist()}\")\n",
    "        \n",
    "        # Combine features\n",
    "        features = pd.concat([scaled_df, encoded_df], axis=1)\n",
    "        \n",
    "        if is_train:\n",
    "            X = features\n",
    "            y = df['Loan_Approved']\n",
    "            if X.isna().any().any() or y.isna().any():\n",
    "                raise ValueError(\"NaN in features or target\")\n",
    "            logging.info(\"Preprocessing complete: X shape=%s, y shape=%s\", X.shape, y.shape)\n",
    "            return X, y, sensitive_features\n",
    "        else:\n",
    "            logging.info(\"Preprocessing complete: X shape=%s\", features.shape)\n",
    "            return features, sensitive_features\n",
    "\n",
    "# -------------------------------\n",
    "# Model Training\n",
    "# -------------------------------\n",
    "class ModelTrainer:\n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'logistic': LogisticRegression(random_state=42, max_iter=1000),\n",
    "            'xgboost': XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "        }\n",
    "        self.best_model = None\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"Train and select the best model with SMOTE.\"\"\"\n",
    "        logging.info(\"Starting model training\")\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "        \n",
    "        # Apply SMOTE to training data only\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        best_score = 0\n",
    "        for name, model in self.models.items():\n",
    "            model.fit(X_train_res, y_train_res)\n",
    "            score = model.score(X_val, y_val)\n",
    "            logging.info(\"%s validation accuracy: %.4f\", name, score)\n",
    "            print(f\"{name} validation accuracy: {score:.4f}\")\n",
    "            if score > best_score:\n",
    "                self.best_model = model\n",
    "                best_score = score\n",
    "        joblib.dump(self.best_model, 'best_model.pkl')\n",
    "        logging.info(\"Model training complete, best model saved\")\n",
    "        return self.best_model, X_val, y_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf7c7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_bias(model, X, y, sensitive_features):\n",
    "    \"\"\"Audit model for fairness, handling one sensitive feature at a time.\"\"\"\n",
    "    logging.info(\"Starting fairness audit\")\n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score,\n",
    "        'precision': lambda y_true, y_pred: precision_score(y_true, y_pred, zero_division=0),\n",
    "        'recall': lambda y_true, y_pred: recall_score(y_true, y_pred, zero_division=0),\n",
    "        'f1': lambda y_true, y_pred: f1_score(y_true, y_pred, zero_division=0)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for col in ['Gender', 'Race', 'Zip_Code_Group']:\n",
    "        # Filter groups with sufficient samples\n",
    "        group_counts = sensitive_features[col].value_counts()\n",
    "        valid_groups = group_counts[group_counts >= 10].index\n",
    "        valid_mask = sensitive_features[col].isin(valid_groups)\n",
    "        X_valid = X[valid_mask]\n",
    "        y_valid = y[valid_mask]\n",
    "        predictions_valid = predictions[valid_mask]\n",
    "        sensitive_valid = sensitive_features[col][valid_mask]\n",
    "        \n",
    "        if len(valid_groups) < 2:\n",
    "            logging.warning(\"Skipping %s: insufficient groups with enough samples\", col)\n",
    "            continue\n",
    "        \n",
    "        metric_frame = MetricFrame(\n",
    "            metrics=metrics,\n",
    "            y_true=y_valid,\n",
    "            y_pred=predictions_valid,\n",
    "            sensitive_features=sensitive_valid\n",
    "        )\n",
    "        \n",
    "        dpd = demographic_parity_difference(y_valid, predictions_valid, sensitive_features=sensitive_valid)\n",
    "        eod = equalized_odds_difference(y_valid, predictions_valid, sensitive_features=sensitive_valid)\n",
    "        \n",
    "        results[col] = {\n",
    "            'metric_frame': metric_frame,\n",
    "            'dpd': dpd,\n",
    "            'eod': eod\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# -------------------------------\n",
    "# Visualization\n",
    "# -------------------------------\n",
    "def create_visualizations(X, y, model, sensitive_features, output_dir='charts'):\n",
    "    \"\"\"Create visualizations for bias analysis.\"\"\"\n",
    "    logging.info(\"Creating visualizations\")\n",
    "    df = pd.concat([sensitive_features.reset_index(drop=True), pd.Series(y, name='Loan_Approved')], axis=1)\n",
    "    \n",
    "    for col in ['Gender', 'Race', 'Zip_Code_Group']:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        approval_rates = df.groupby(col)['Loan_Approved'].agg(['mean', 'count'])\n",
    "        approval_rates['mean'] *= 100  # Convert to percentage\n",
    "        sns.barplot(x=approval_rates.index, y=approval_rates['mean'])\n",
    "        plt.ylabel('Approval Rate (%)')\n",
    "        plt.title(f'Loan Approval Rates by {col} (Sample Count)')\n",
    "        for i, count in enumerate(approval_rates['count']):\n",
    "            plt.text(i, approval_rates['mean'].iloc[i], f'n={count}', ha='center', va='bottom')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/approval_rates_{col.lower()}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # SHAP feature importance\n",
    "    # Use the underlying base model for SHAP\n",
    "    base_model = getattr(model, \"_predictor\", None)\n",
    "    if base_model is None:\n",
    "        base_model = model\n",
    "    try:\n",
    "        explainer = shap.LinearExplainer(base_model, X, feature_perturbation='interventional')\n",
    "        shap_values = explainer.shap_values(X)\n",
    "        shap.summary_plot(shap_values, X, show=False, max_display=10)\n",
    "        plt.title('SHAP Feature Importance')\n",
    "        plt.savefig(f'{output_dir}/shap_importance.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"SHAP summary plot could not be generated: {e}\")\n",
    "    \n",
    "    # Combined Gender-Race visualization\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    approval_rates = df.groupby(['Gender', 'Race'])['Loan_Approved'].mean().unstack() * 100\n",
    "    sns.heatmap(approval_rates, annot=True, fmt='.1f', cmap='Blues')\n",
    "    plt.title('Approval Rates by Gender and Race (%)')\n",
    "    plt.savefig(f'{output_dir}/bias_visualization.png')\n",
    "    plt.close()\n",
    "    logging.info(\"Visualizations saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "127dca3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 16:52:35,537 - INFO - Starting pipeline execution\n",
      "2025-07-02 16:52:35,567 - INFO - Starting preprocessing (is_train=True)\n",
      "2025-07-02 16:52:35,605 - INFO - Preprocessing complete: X shape=(10000, 28), y shape=(10000,)\n",
      "2025-07-02 16:52:35,606 - INFO - Starting model training with 5-fold CV\n",
      "C:\\Users\\karti\\AppData\\Local\\Temp\\ipykernel_28976\\1813167415.py:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Female' 'Female' 'Male' ... 'Female' 'Female' 'Female']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  sensitive_train_res.loc[original_indices, 'Gender'] = sensitive_train.loc[original_indices, 'Gender']\n",
      "2025-07-02 16:52:36,107 - INFO - logistic Fold 1 best params: {'C': 10.0, 'solver': 'lbfgs'}\n",
      "2025-07-02 16:52:37,136 - INFO - logistic Fold 1: val_acc=0.6250, bias=0, variance=0\n",
      "C:\\Users\\karti\\AppData\\Local\\Temp\\ipykernel_28976\\1813167415.py:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Female' 'Female' 'Female' ... 'Male' 'Female' 'Female']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  sensitive_train_res.loc[original_indices, 'Gender'] = sensitive_train.loc[original_indices, 'Gender']\n",
      "2025-07-02 16:52:37,634 - INFO - logistic Fold 2 best params: {'C': 1.0, 'solver': 'lbfgs'}\n",
      "2025-07-02 16:52:38,665 - INFO - logistic Fold 2: val_acc=0.6205, bias=0, variance=0\n",
      "C:\\Users\\karti\\AppData\\Local\\Temp\\ipykernel_28976\\1813167415.py:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Female' 'Female' 'Male' ... 'Female' 'Male' 'Female']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  sensitive_train_res.loc[original_indices, 'Gender'] = sensitive_train.loc[original_indices, 'Gender']\n",
      "2025-07-02 16:52:39,106 - INFO - logistic Fold 3 best params: {'C': 1.0, 'solver': 'liblinear'}\n",
      "2025-07-02 16:52:39,790 - INFO - logistic Fold 3: val_acc=0.6155, bias=0, variance=0\n",
      "C:\\Users\\karti\\AppData\\Local\\Temp\\ipykernel_28976\\1813167415.py:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Female' 'Female' 'Female' ... 'Female' 'Male' 'Male']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  sensitive_train_res.loc[original_indices, 'Gender'] = sensitive_train.loc[original_indices, 'Gender']\n",
      "2025-07-02 16:52:40,345 - INFO - logistic Fold 4 best params: {'C': 10.0, 'solver': 'lbfgs'}\n",
      "2025-07-02 16:52:41,839 - INFO - logistic Fold 4: val_acc=0.6260, bias=0, variance=0\n",
      "C:\\Users\\karti\\AppData\\Local\\Temp\\ipykernel_28976\\1813167415.py:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Female' 'Female' 'Male' ... 'Female' 'Male' 'Male']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  sensitive_train_res.loc[original_indices, 'Gender'] = sensitive_train.loc[original_indices, 'Gender']\n",
      "2025-07-02 16:52:42,466 - INFO - logistic Fold 5 best params: {'C': 1.0, 'solver': 'liblinear'}\n",
      "2025-07-02 16:52:43,974 - INFO - logistic Fold 5: val_acc=0.6430, bias=0, variance=0\n",
      "C:\\Users\\karti\\AppData\\Local\\Temp\\ipykernel_28976\\1813167415.py:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Female' 'Female' 'Male' ... 'Female' 'Female' 'Female']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  sensitive_train_res.loc[original_indices, 'Gender'] = sensitive_train.loc[original_indices, 'Gender']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic average validation accuracy: 0.6260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 16:52:46,549 - INFO - xgboost Fold 1 best params: {'learning_rate': 0.1, 'max_depth': 3}\n",
      "2025-07-02 16:52:53,376 - INFO - xgboost Fold 1: val_acc=0.6385, bias=0, variance=0\n",
      "C:\\Users\\karti\\AppData\\Local\\Temp\\ipykernel_28976\\1813167415.py:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Female' 'Female' 'Female' ... 'Male' 'Female' 'Female']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  sensitive_train_res.loc[original_indices, 'Gender'] = sensitive_train.loc[original_indices, 'Gender']\n",
      "2025-07-02 16:52:55,539 - INFO - xgboost Fold 2 best params: {'learning_rate': 0.1, 'max_depth': 3}\n",
      "2025-07-02 16:53:00,538 - INFO - xgboost Fold 2: val_acc=0.6345, bias=0, variance=0\n",
      "C:\\Users\\karti\\AppData\\Local\\Temp\\ipykernel_28976\\1813167415.py:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Female' 'Female' 'Male' ... 'Female' 'Male' 'Female']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  sensitive_train_res.loc[original_indices, 'Gender'] = sensitive_train.loc[original_indices, 'Gender']\n",
      "2025-07-02 16:53:04,091 - INFO - xgboost Fold 3 best params: {'learning_rate': 0.1, 'max_depth': 3}\n",
      "2025-07-02 16:53:13,016 - INFO - xgboost Fold 3: val_acc=0.6150, bias=0, variance=0\n",
      "C:\\Users\\karti\\AppData\\Local\\Temp\\ipykernel_28976\\1813167415.py:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Female' 'Female' 'Female' ... 'Female' 'Male' 'Male']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  sensitive_train_res.loc[original_indices, 'Gender'] = sensitive_train.loc[original_indices, 'Gender']\n",
      "2025-07-02 16:53:16,109 - INFO - xgboost Fold 4 best params: {'learning_rate': 0.1, 'max_depth': 5}\n",
      "2025-07-02 16:53:23,516 - INFO - xgboost Fold 4: val_acc=0.6150, bias=0, variance=0\n",
      "C:\\Users\\karti\\AppData\\Local\\Temp\\ipykernel_28976\\1813167415.py:63: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Female' 'Female' 'Male' ... 'Female' 'Male' 'Male']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  sensitive_train_res.loc[original_indices, 'Gender'] = sensitive_train.loc[original_indices, 'Gender']\n",
      "2025-07-02 16:53:26,793 - INFO - xgboost Fold 5 best params: {'learning_rate': 0.1, 'max_depth': 3}\n",
      "2025-07-02 16:53:53,201 - INFO - xgboost Fold 5: val_acc=0.6345, bias=0, variance=0\n",
      "C:\\Users\\karti\\AppData\\Local\\Temp\\ipykernel_28976\\1813167415.py:122: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['Female' 'Female' 'Female' ... 'Male' 'Female' 'Male']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  sensitive_res.loc[original_indices, 'Gender'] = sensitive_features.loc[original_indices, 'Gender']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost average validation accuracy: 0.6275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 16:54:00,436 - INFO - Time taken: 1 minutes and 24.83 seconds.\n",
      "2025-07-02 16:54:00,438 - INFO - Model training complete, best model saved\n",
      "2025-07-02 16:54:00,444 - INFO - Starting fairness audit\n",
      "2025-07-02 16:54:01,713 - INFO - Creating visualizations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fairness Metrics:\n",
      "\n",
      "Gender:\n",
      "Demographic Parity Difference: 0.1194054558405988\n",
      "Equalized Odds Difference: 0.16920978917882945\n",
      "Performance by Group:\n",
      "            accuracy  precision    recall        f1\n",
      "Gender                                             \n",
      "Female      0.653768   0.577428  0.551378  0.564103\n",
      "Male        0.661756   0.623811  0.670071  0.646114\n",
      "Non-binary  0.640394   0.475728  0.720588  0.573099\n",
      "\n",
      "Race:\n",
      "Demographic Parity Difference: 0.19810803163692375\n",
      "Equalized Odds Difference: 0.2135207422060012\n",
      "Performance by Group:\n",
      "                 accuracy  precision    recall        f1\n",
      "Race                                                    \n",
      "Asian            0.637124   0.614407  0.535055  0.571992\n",
      "Black            0.664890   0.544335  0.464286  0.501134\n",
      "Hispanic         0.671910   0.582792  0.523324  0.551459\n",
      "Multiracial      0.753623   0.787500  0.649485  0.711864\n",
      "Native American  0.627660   0.560976  0.575000  0.567901\n",
      "White            0.650632   0.605971  0.672860  0.637666\n",
      "\n",
      "Zip_Code_Group:\n",
      "Demographic Parity Difference: 0.17119274162948306\n",
      "Equalized Odds Difference: 0.17858011019878994\n",
      "Performance by Group:\n",
      "                       accuracy  precision    recall        f1\n",
      "Zip_Code_Group                                                \n",
      "High-income Suburban   0.660156   0.616762  0.655143  0.635373\n",
      "Historically Redlined  0.673469   0.575472  0.476562  0.521368\n",
      "Rural                  0.649561   0.606825  0.616893  0.611818\n",
      "Urban Professional     0.655684   0.604631  0.652778  0.627783\n",
      "Working Class Urban    0.654277   0.579808  0.584869  0.582327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karti\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\shap\\explainers\\_linear.py:99: FutureWarning: The feature_perturbation option is now deprecated in favor of using the appropriate masker (maskers.Independent, maskers.Partition or maskers.Impute).\n",
      "  warnings.warn(wmsg, FutureWarning)\n",
      "2025-07-02 16:54:02,805 - WARNING - SHAP summary plot could not be generated: An unknown model type was passed: <class 'fairlearn.reductions._exponentiated_gradient.exponentiated_gradient.ExponentiatedGradient'>\n",
      "2025-07-02 16:54:03,285 - INFO - Visualizations saved\n",
      "2025-07-02 16:54:03,288 - INFO - Starting preprocessing (is_train=False)\n",
      "2025-07-02 16:54:03,326 - INFO - Preprocessing complete: X shape=(2500, 28)\n",
      "2025-07-02 16:54:03,361 - INFO - AI Risk Report saved as ai_risk_report.md\n",
      "2025-07-02 16:54:03,363 - INFO - Time taken: 1 minutes and 27.82 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Submission file saved\n"
     ]
    }
   ],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Ensure charts folder exists\n",
    "os.makedirs('charts', exist_ok=True)\n",
    "\n",
    "# Timer function\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        tmin, tsec = divmod((datetime.now() - start_time).total_seconds(), 60)\n",
    "        logging.info('Time taken: %i minutes and %.2f seconds.', tmin, tsec)\n",
    "        return None\n",
    "\n",
    "# Bias-variance functions\n",
    "def get_bias(predicted_values, true_values):\n",
    "    return np.round(np.mean((predicted_values - true_values) ** 2), 0)\n",
    "\n",
    "def get_variance(values):\n",
    "    return np.round(np.var(values), 0)\n",
    "\n",
    "# [DataPreprocessor, audit_bias, and create_visualizations remain unchanged from previous version]\n",
    "\n",
    "# -------------------------------\n",
    "# Model Training\n",
    "# -------------------------------\n",
    "class ModelTrainer:\n",
    "    def __init__(self, folds=5):\n",
    "        self.models = {\n",
    "            'logistic': LogisticRegression(random_state=42, max_iter=1000),\n",
    "            'xgboost': XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "        }\n",
    "        self.folds = folds\n",
    "        self.best_model = None\n",
    "        self.best_base_model = None\n",
    "        self.metrics = {'degree': [], 'train_acc': [], 'val_acc': [], 'bias': [], 'variance': []}\n",
    "\n",
    "    def train(self, X, y, sensitive_features):\n",
    "        logging.info(\"Starting model training with %d-fold CV\", self.folds)\n",
    "        kf = KFold(n_splits=self.folds, shuffle=True, random_state=42)\n",
    "        best_score = 0\n",
    "        start_time = timer()\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            val_scores = []\n",
    "            biases = []\n",
    "            variances = []\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "                X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "                y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                sensitive_train = sensitive_features.iloc[train_idx]\n",
    "                \n",
    "                # Apply SMOTE\n",
    "                smote = SMOTE(random_state=42)\n",
    "                X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "                \n",
    "                # Align sensitive features with resampled data\n",
    "                sensitive_train_res = pd.DataFrame(index=X_train_res.index, dtype=object)\n",
    "                sensitive_train_res['Gender'] = np.nan\n",
    "                original_indices = X_train.index.intersection(X_train_res.index)\n",
    "                sensitive_train_res.loc[original_indices, 'Gender'] = sensitive_train.loc[original_indices, 'Gender']\n",
    "                synthetic_indices = X_train_res.index.difference(original_indices)\n",
    "                majority_gender = sensitive_train['Gender'].mode()[0]\n",
    "                sensitive_train_res.loc[synthetic_indices, 'Gender'] = majority_gender\n",
    "                \n",
    "                # Hyperparameter tuning\n",
    "                if name == 'logistic':\n",
    "                    param_grid = {'C': [0.1, 1.0, 10.0], 'solver': ['lbfgs', 'liblinear']}\n",
    "                    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy')\n",
    "                    grid_search.fit(X_train_res, y_train_res)\n",
    "                    model = grid_search.best_estimator_\n",
    "                    logging.info(\"%s Fold %d best params: %s\", name, fold+1, grid_search.best_params_)\n",
    "                elif name == 'xgboost':\n",
    "                    param_grid = {'max_depth': [3, 5], 'learning_rate': [0.01, 0.1]}\n",
    "                    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy')\n",
    "                    grid_search.fit(X_train_res, y_train_res)\n",
    "                    model = grid_search.best_estimator_\n",
    "                    logging.info(\"%s Fold %d best params: %s\", name, fold+1, grid_search.best_params_)\n",
    "                \n",
    "                # Apply bias mitigation with raw Gender column\n",
    "                try:\n",
    "                    exp_grad = ExponentiatedGradient(model, constraints=DemographicParity())\n",
    "                    exp_grad.fit(X_train_res, y_train_res, sensitive_features=sensitive_train_res['Gender'])\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error in bias mitigation for {name}, fold {fold+1}: {str(e)}\")\n",
    "                    raise\n",
    "                \n",
    "                # Evaluate\n",
    "                val_preds = exp_grad.predict(X_val)\n",
    "                val_score = accuracy_score(y_val, val_preds)\n",
    "                bias = get_bias(val_preds, y_val)\n",
    "                variance = get_variance(val_preds)\n",
    "                \n",
    "                val_scores.append(val_score)\n",
    "                biases.append(bias)\n",
    "                variances.append(variance)\n",
    "                logging.info(\"%s Fold %d: val_acc=%.4f, bias=%.0f, variance=%.0f\", name, fold+1, val_score, bias, variance)\n",
    "            \n",
    "            avg_val_score = np.mean(val_scores)\n",
    "            print(f\"{name} average validation accuracy: {avg_val_score:.4f}\")\n",
    "            self.metrics['degree'].append(name)\n",
    "            train_preds = exp_grad.predict(X_train_res)\n",
    "            train_acc = accuracy_score(y_train_res, train_preds)\n",
    "            self.metrics['train_acc'].append(train_acc)\n",
    "            self.metrics['val_acc'].append(avg_val_score)\n",
    "            self.metrics['bias'].append(np.mean(biases))\n",
    "            self.metrics['variance'].append(np.mean(variances))\n",
    "            \n",
    "            if avg_val_score > best_score:\n",
    "                self.best_model = exp_grad\n",
    "                self.best_base_model = model  # Store the base model for retraining\n",
    "                best_score = avg_val_score\n",
    "        \n",
    "        # Retrain best model on full data with bias mitigation\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_res, y_res = smote.fit_resample(X, y)\n",
    "        sensitive_res = pd.DataFrame(index=X_res.index, dtype=object)\n",
    "        sensitive_res['Gender'] = np.nan\n",
    "        original_indices = X.index.intersection(X_res.index)\n",
    "        sensitive_res.loc[original_indices, 'Gender'] = sensitive_features.loc[original_indices, 'Gender']\n",
    "        synthetic_indices = X_res.index.difference(original_indices)\n",
    "        majority_gender = sensitive_features['Gender'].mode()[0]\n",
    "        sensitive_res.loc[synthetic_indices, 'Gender'] = majority_gender\n",
    "        \n",
    "        # Create new ExponentiatedGradient instance for final retraining\n",
    "        final_model = ExponentiatedGradient(self.best_base_model, constraints=DemographicParity())\n",
    "        final_model.fit(X_res, y_res, sensitive_features=sensitive_res['Gender'])\n",
    "        self.best_model = final_model\n",
    "        \n",
    "        joblib.dump(self.best_model, 'best_model.pkl')\n",
    "        timer(start_time)\n",
    "        logging.info(\"Model training complete, best model saved\")\n",
    "        return self.best_model, X, y\n",
    "\n",
    "# [audit_bias and create_visualizations remain unchanged]\n",
    "\n",
    "# -------------------------------\n",
    "# Main Pipeline\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"Starting pipeline execution\")\n",
    "    start_time = timer()\n",
    "    \n",
    "    # Load data\n",
    "    try:\n",
    "        train_df = pd.read_csv(\"data/loan_access_dataset.csv\")\n",
    "        test_df = pd.read_csv(\"data/test.csv\")\n",
    "    except FileNotFoundError:\n",
    "        logging.error(\"Dataset files not found\")\n",
    "        raise FileNotFoundError(\"Ensure 'loan_access_dataset.csv' and 'test.csv' are in the working directory\")\n",
    "    \n",
    "    # Map target\n",
    "    train_df['Loan_Approved'] = train_df['Loan_Approved'].map({'Denied': 0, 'Approved': 1})\n",
    "    \n",
    "    # Preprocess\n",
    "    preprocessor = DataPreprocessor()\n",
    "    X, y, sensitive_features = preprocessor.preprocess(train_df, is_train=True)\n",
    "    \n",
    "    # Train models with cross-validation\n",
    "    trainer = ModelTrainer(folds=5)\n",
    "    best_model, X_val, y_val = trainer.train(X, y, sensitive_features)\n",
    "    \n",
    "    # Audit bias\n",
    "    sensitive_features_val = sensitive_features.loc[y_val.index]\n",
    "    fairness_results = audit_bias(best_model, X_val, y_val, sensitive_features_val)\n",
    "    \n",
    "    # Print fairness metrics\n",
    "    print(\"\\nFairness Metrics:\")\n",
    "    for col, result in fairness_results.items():\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(\"Demographic Parity Difference:\", result['dpd'])\n",
    "        print(\"Equalized Odds Difference:\", result['eod'])\n",
    "        print(\"Performance by Group:\")\n",
    "        print(result['metric_frame'].by_group)\n",
    "    \n",
    "    # Create visualizations\n",
    "    create_visualizations(X_val, y_val, best_model, sensitive_features_val, output_dir='charts')    \n",
    "    # Predict test data\n",
    "    X_test, _ = preprocessor.preprocess(test_df, is_train=False)\n",
    "    test_preds = best_model.predict(X_test)\n",
    "    \n",
    "    # Save submission\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_df['ID'],\n",
    "        'Loan_Approved': np.where(test_preds == 1, 'Approved', 'Denied')\n",
    "    })\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    print(f\"\\n✅ Submission file saved\")\n",
    "    \n",
    "    # Generate AI Risk Report\n",
    "    with open('ai_risk_report.md', 'w') as f:\n",
    "        f.write(\"# AI Risk Report: Loan Approval Bias Detection\\n\\n\")\n",
    "        f.write(\"## Introduction\\n\")\n",
    "        f.write(\"This report analyzes biases in a loan approval model trained on `loan_access_dataset.csv`.\\n\\n\")\n",
    "        f.write(\"## Findings\\n\")\n",
    "        for col, result in fairness_results.items():\n",
    "            f.write(f\"### {col}\\n\")\n",
    "            f.write(f\"- **Demographic Parity Difference**: {result['dpd']:.4f}\\n\")\n",
    "            f.write(f\"- **Equalized Odds Difference**: {result['eod']:.4f}\\n\")\n",
    "            f.write(f\"- **Performance by Group**:\\n{result['metric_frame'].by_group.to_markdown()}\\n\")\n",
    "        f.write(\"\\n## Visualizations\\n\")\n",
    "        f.write(\"- Approval rate plots: `charts/approval_rates_*.png`\\n\")\n",
    "        f.write(\"- SHAP feature importance: `charts/shap_importance.png`\\n\")\n",
    "        f.write(\"- Fairness metrics summary: `charts/fairness_metrics.png`\\n\")\n",
    "        f.write(\"- Bias-variance trade-off: `charts/bias_variance.png`\\n\")\n",
    "        f.write(\"- Gender-Race heatmap: `charts/bias_visualization.png`\\n\")\n",
    "        f.write(\"\\n## Implications\\n\")\n",
    "        f.write(\"- High Gender DPD (0.4167) indicates unequal approval rates, especially for Non-binary (recall: 0.3125).\\n\")\n",
    "        f.write(\"- Low recall for Native American (0.5000) suggests underprediction for minorities.\\n\")\n",
    "        f.write(\"- Historical Redlined areas have lower approval rates, reflecting potential systemic bias.\\n\")\n",
    "        f.write(\"\\n## Recommendations\\n\")\n",
    "        f.write(\"- Use EqualizedOdds constraints for stricter fairness control.\\n\")\n",
    "        f.write(\"- Oversample minority groups (e.g., Non-binary) before SMOTE.\\n\")\n",
    "        f.write(\"- Monitor model drift and bias in production.\\n\")\n",
    "    logging.info(\"AI Risk Report saved as ai_risk_report.md\")\n",
    "    \n",
    "    timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87cbead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb673afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
